#!/usr/bin/env python3
"""
æ¸…æ´—markdownæ–‡æ¡£
åˆ é™¤å›¾ç‰‡é“¾æ¥å’ŒFigureå¼€å¤´çš„è¡Œ
"""
import re
from pathlib import Path

def show_all_headings(file_path):
    """
    æ˜¾ç¤ºmarkdownæ–‡ä»¶ä¸­æ‰€æœ‰çš„æ ‡é¢˜ï¼ˆä»¥#å¼€å¤´çš„è¡Œï¼‰
    Args:
        file_path (str): markdownæ–‡ä»¶è·¯å¾„
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    lines = content.split('\n')
    headings = []
    
    print("ğŸ“‹ æ–‡æ¡£ä¸­æ‰€æœ‰æ ‡é¢˜:")
    print("=" * 50)
    
    for i, line in enumerate(lines, 1):
        if line.strip().startswith('#'):
            headings.append((i, line.strip()))
            print(f"ç¬¬{i}è¡Œ: {line.strip()}")
    
    print("=" * 50)
    print(f"å…±æ‰¾åˆ° {len(headings)} ä¸ªæ ‡é¢˜")
    print()
    
    return headings

def analyze_heading_structure(lines):
    """
    åˆ†ææ–‡æ¡£çš„æ ‡é¢˜ç»“æ„ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ç‰¹æ®Šå¤„ç†
    Args:
        lines (list): æ–‡æ¡£è¡Œåˆ—è¡¨
    Returns:
        dict: åˆ†æç»“æœ
    """
    headings = []
    for i, line in enumerate(lines):
        if line.strip().startswith('#'):
            # æ£€æŸ¥æ ‡é¢˜çº§åˆ«
            level = len(line.strip()) - len(line.strip().lstrip('#'))
            headings.append({
                'line_index': i,
                'level': level,
                'content': line.strip(),
                'has_roman': bool(re.match(r'^\s*#+\s*([IVX]+)\.?\s+', line.strip())),
                'has_letter': bool(re.match(r'^\s*#+\s*([A-Z])\.?\s+', line.strip())),
                'has_number': bool(re.match(r'^\s*#+\s*(\d+(?:[\.\s]+\d+)*?)[\.\s]*\s+', line.strip()))
            })
    
    # åˆ¤æ–­æ˜¯å¦æ‰€æœ‰æ ‡é¢˜éƒ½æ˜¯ä¸€çº§æ ‡é¢˜ä¸”æ²¡æœ‰ç‰¹æ®Šæ ¼å¼
    all_level_1 = all(h['level'] == 1 for h in headings)
    no_special_format = all(not (h['has_roman'] or h['has_letter'] or h['has_number']) for h in headings)
    
    return {
        'headings': headings,
        'all_level_1': all_level_1,
        'no_special_format': no_special_format,
        'needs_default_adjustment': all_level_1 and no_special_format and len(headings) > 1
    }

def adjust_heading_levels(line):
    """
    æ ¹æ®æ ‡é¢˜ä¸­æ•°å­—ã€ç½—é©¬æ•°å­—ã€å­—æ¯çš„ä¸ªæ•°è°ƒæ•´æ ‡é¢˜çº§åˆ«
    Args:
        line (str): æ ‡é¢˜è¡Œ
    Returns:
        str: è°ƒæ•´åçš„æ ‡é¢˜è¡Œ
    """
    # 1. åŒ¹é…ç½—é©¬æ•°å­—æ ¼å¼ï¼š# I. INTRODUCTION, # II. METHODS ç­‰
    roman_match = re.match(r'^(#+)\s*([IVX]+)\.?\s+(.*)', line.strip())
    if roman_match:
        current_hashes, roman, title = roman_match.groups()
        # ç½—é©¬æ•°å­—æ ‡é¢˜è®¾ä¸ºäºŒçº§æ ‡é¢˜
        new_level = 2
        new_hashes = '#' * new_level
        new_line = f"{new_hashes} {roman}. {title}"
        
        if len(current_hashes) != new_level:
            print(f"ğŸ”§ è°ƒæ•´ç½—é©¬æ•°å­—æ ‡é¢˜çº§åˆ«: {line.strip()[:50]}... -> {new_line[:50]}...")
            return new_line
        return line
    
    # 2. åŒ¹é…å­—æ¯æ ¼å¼ï¼š# A anything, # B anything ç­‰
    letter_match = re.match(r'^(#+)\s*([A-Z])\.?\s+(.*)', line.strip())
    if letter_match:
        current_hashes, letter, title = letter_match.groups()
        # å­—æ¯æ ‡é¢˜è®¾ä¸ºä¸‰çº§æ ‡é¢˜
        new_level = 3
        new_hashes = '#' * new_level
        new_line = f"{new_hashes} {letter} {title}"
        
        if len(current_hashes) != new_level:
            print(f"ğŸ”§ è°ƒæ•´å­—æ¯æ ‡é¢˜çº§åˆ«: {line.strip()[:50]}... -> {new_line[:50]}...")
            return new_line
        return line
    
    # 3. åŒ¹é…æ•°å­—æ ¼å¼ï¼š# æ•°å­—[.ç©ºæ ¼]æ•°å­—[.ç©ºæ ¼]æ•°å­—... æ ‡é¢˜å†…å®¹
    number_match = re.match(r'^(#+)\s*(\d+(?:[\.\s]+\d+)*?)[\.\s]*\s+(.*)', line.strip())
    if number_match:
        current_hashes, numbers_part, title = number_match.groups()
        
        # æå–æ‰€æœ‰æ•°å­—ï¼ˆå¿½ç•¥ç‚¹å’Œç©ºæ ¼ï¼‰
        numbers = re.findall(r'\d+', numbers_part)
        num_count = len(numbers)
        
        # æ ¹æ®æ•°å­—ä¸ªæ•°ç¡®å®šæ ‡é¢˜çº§åˆ«ï¼ˆæœ€å¤š5çº§ï¼‰
        new_level = min(num_count + 1, 5)
        new_hashes = '#' * new_level
        
        # é‡æ–°æ„å»ºæ•°å­—éƒ¨åˆ†ï¼Œä½¿ç”¨æ ‡å‡†æ ¼å¼ï¼ˆæ•°å­—.æ•°å­—.æ•°å­—ï¼‰
        if num_count == 1:
            formatted_numbers = numbers[0]
        else:
            formatted_numbers = '.'.join(numbers)
        
        new_line = f"{new_hashes} {formatted_numbers} {title}"
        
        if len(current_hashes) != new_level:
            print(f"ğŸ”§ è°ƒæ•´æ•°å­—æ ‡é¢˜çº§åˆ«: {line.strip()[:50]}... -> {new_line[:50]}...")
            return new_line
    
    return line

def clean_markdown_file(file_path):
    """
    æ¸…æ´—markdownæ–‡ä»¶ï¼Œåˆ é™¤å›¾ç‰‡é“¾æ¥å’ŒFigureå¼€å¤´çš„è¡Œ
    Args:
        file_path (str): markdownæ–‡ä»¶è·¯å¾„
    """
    # è¯»å–æ–‡ä»¶å†…å®¹
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    print(f"ğŸš€ å¼€å§‹æ¸…æ´—æ–‡ä»¶: {file_path}")
    print(f"ğŸ“„ åŸå§‹æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
    
    # æŒ‰è¡Œåˆ†å‰²å†…å®¹
    lines = content.split('\n')
    
    # åˆ†ææ ‡é¢˜ç»“æ„
    heading_analysis = analyze_heading_structure(lines)
    if heading_analysis['needs_default_adjustment']:
        print(f"ğŸ“ æ£€æµ‹åˆ°æ‰€æœ‰æ ‡é¢˜å‡ä¸ºä¸€çº§æ ‡é¢˜ä¸”æ— ç‰¹æ®Šæ ¼å¼ï¼Œå°†åº”ç”¨é»˜è®¤è°ƒæ•´è§„åˆ™")
    
    cleaned_lines = []
    removed_images = 0
    removed_figures = 0
    removed_references = False
    removed_acknowledgements = False
    removed_appendix = False
    adjusted_headings = 0
    first_heading_processed = False
    
    for line in lines:
        # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡é“¾æ¥è¡Œ
        # åŒ¹é… ![...](...)ã€<img ...>ã€[image: ...]ç­‰æ ¼å¼
        if re.search(r'!\[.*?\]\(.*?\)|<img.*?>|\[image:.*?\]', line, re.IGNORECASE):
            removed_images += 1
            print(f"ğŸ–¼ï¸ åˆ é™¤å›¾ç‰‡é“¾æ¥: {line[:50]}...")
            continue
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºFigureå¼€å¤´çš„è¡Œæˆ–Fig./FIG.æ•°å­—å¼€å¤´çš„è¡Œ
        if (line.strip().startswith('Figure') or 
            re.match(r'^\s*Fig\.\s*\d+\.?', line, re.IGNORECASE)):
            removed_figures += 1
            print(f"ğŸ“Š åˆ é™¤å›¾æ³¨: {line[:50]}...")
            continue
        
        # è°ƒæ•´æ ‡é¢˜çº§åˆ«
        original_line = line
        
        # å¦‚æœéœ€è¦é»˜è®¤è°ƒæ•´ï¼ˆæ‰€æœ‰æ ‡é¢˜éƒ½æ˜¯ä¸€çº§ä¸”æ— ç‰¹æ®Šæ ¼å¼ï¼‰
        if heading_analysis['needs_default_adjustment'] and line.strip().startswith('#'):
            if not first_heading_processed:
                # ç¬¬ä¸€ä¸ªæ ‡é¢˜ä¿æŒä¸€çº§
                first_heading_processed = True
                print(f"ğŸ”§ ä¿æŒç¬¬ä¸€ä¸ªæ ‡é¢˜ä¸ºä¸€çº§: {line.strip()[:50]}...")
            else:
                # å…¶ä½™æ ‡é¢˜æ”¹ä¸ºäºŒçº§
                if line.strip().startswith('# ') and not line.strip().startswith('## '):
                    line = '##' + line[1:]
                    adjusted_headings += 1
                    print(f"ğŸ”§ è°ƒæ•´æ ‡é¢˜ä¸ºäºŒçº§: {original_line.strip()[:50]}... -> {line.strip()[:50]}...")
        else:
            # ä½¿ç”¨åŸæœ‰çš„æ ‡é¢˜çº§åˆ«è°ƒæ•´é€»è¾‘
            line = adjust_heading_levels(line)
            if line != original_line:
                adjusted_headings += 1
        
        # åœ¨æ ‡é¢˜è°ƒæ•´åæ£€æŸ¥æ˜¯å¦é‡åˆ°éœ€è¦åˆ é™¤çš„éƒ¨åˆ†
        # æ£€æŸ¥æ˜¯å¦é‡åˆ°Referencesæ ‡é¢˜ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼Œå…è®¸å†’å·ç­‰æ ‡ç‚¹ï¼‰
        if re.match(r'^\s*#+\s*references\s*[:\.]?\s*$', line, re.IGNORECASE):
            removed_references = True
            print(f"ğŸ“š å‘ç°Referencesæ ‡é¢˜ï¼Œåˆ é™¤æ­¤å¤„åŠä¹‹åçš„æ‰€æœ‰å†…å®¹: {line[:50]}...")
            break
        
        # æ£€æŸ¥æ˜¯å¦é‡åˆ°Acknowledgementsæ ‡é¢˜ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        if re.match(r'^\s*#+\s*acknowledg.*\s*[:\.]?\s*$', line, re.IGNORECASE):
            removed_acknowledgements = True
            print(f"ğŸ™ å‘ç°Acknowledgementsæ ‡é¢˜ï¼Œåˆ é™¤æ­¤å¤„åŠä¹‹åçš„æ‰€æœ‰å†…å®¹: {line[:50]}...")
            break
        
        # æ£€æŸ¥æ˜¯å¦é‡åˆ°Appendixæ ‡é¢˜ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        if re.match(r'^\s*#+\s*appendix.*', line, re.IGNORECASE):
            removed_appendix = True
            print(f"ğŸ“ å‘ç°Appendixæ ‡é¢˜ï¼Œåˆ é™¤æ­¤å¤„åŠä¹‹åçš„æ‰€æœ‰å†…å®¹: {line[:50]}...")
            break
        
        # ä¿ç•™å…¶ä»–è¡Œ
        cleaned_lines.append(line)
    
    # é‡æ–°ç»„åˆå†…å®¹
    cleaned_content = '\n'.join(cleaned_lines)
    
    # å†™å›æ–‡ä»¶
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(cleaned_content)
    
    print(f"âœ… æ¸…æ´—å®Œæˆ!")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - åˆ é™¤å›¾ç‰‡é“¾æ¥: {removed_images} ä¸ª")
    print(f"   - åˆ é™¤å›¾æ³¨è¡Œ: {removed_figures} ä¸ª")
    print(f"   - è°ƒæ•´æ ‡é¢˜çº§åˆ«: {adjusted_headings} ä¸ª")
    print(f"   - åˆ é™¤Referenceséƒ¨åˆ†: {'æ˜¯' if removed_references else 'å¦'}")
    print(f"   - åˆ é™¤Acknowledgementséƒ¨åˆ†: {'æ˜¯' if removed_acknowledgements else 'å¦'}")
    print(f"   - åˆ é™¤Appendixéƒ¨åˆ†: {'æ˜¯' if removed_appendix else 'å¦'}")
    print(f"   - æ¸…æ´—åå¤§å°: {len(cleaned_content)} å­—ç¬¦")
    print(f"   - å‡å°‘å†…å®¹: {len(content) - len(cleaned_content)} å­—ç¬¦")

def main():
    """ä¸»å‡½æ•°"""
    # ç›®æ ‡æ–‡ä»¶è·¯å¾„
    file_path = "/home/wang2go/Code/CNOOC_RAG/CNOOC_RAG/data/01_data/arxiv_md/1401.5546.md"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(file_path).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    # é¦–å…ˆæ˜¾ç¤ºæ‰€æœ‰æ ‡é¢˜
    show_all_headings(file_path)
    
    # æ¸…æ´—æ–‡ä»¶
    clean_markdown_file(file_path)

if __name__ == "__main__":
    main()