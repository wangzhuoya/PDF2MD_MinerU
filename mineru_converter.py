#!/usr/bin/env python3
"""
å®Œæ•´çš„MinerU PDFè½¬Markdownè½¬æ¢è„šæœ¬
åŒ…å«ä¸Šä¼ ã€ç­‰å¾…å¤„ç†ã€ä¸‹è½½å’Œè§£å‹åŠŸèƒ½
"""

import requests
import time
import os
import zipfile
from pathlib import Path
import json
from dotenv import load_dotenv

class MinerUConverter:
    def __init__(self, token):
        if not token:
            raise ValueError("MinerU API token is required.")
        self.token = token
        self.base_url = "https://mineru.net"
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {token}"
        }
    
    def upload_and_convert_pdf(self, pdf_path, output_dir="data/01_data/arxiv_md", max_wait_time=600):
        """
        å®Œæ•´çš„PDFè½¬æ¢æµç¨‹ï¼šä¸Šä¼  -> ç­‰å¾…å¤„ç† -> ä¸‹è½½ -> è§£å‹
        
        Args:
            pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
            output_dir (str): è¾“å‡ºç›®å½•
            max_wait_time (int): æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        
        Returns:
            bool: è½¬æ¢æ˜¯å¦æˆåŠŸ
        """
        pdf_file = Path(pdf_path)
        if not pdf_file.exists():
            print(f"âŒ PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
            return False
        
        print(f"ğŸš€ å¼€å§‹è½¬æ¢PDF: {pdf_file.name}")
        
        # æ­¥éª¤1: ç”³è¯·ä¸Šä¼ URL
        batch_id = self._request_upload_urls([pdf_file.name])
        if not batch_id:
            return False
        
        # æ­¥éª¤2: ä¸Šä¼ PDFæ–‡ä»¶
        if not self._upload_pdf_file(batch_id, pdf_path):
            return False
        
        # æ­¥éª¤3: ç­‰å¾…å¤„ç†å®Œæˆ
        download_url = self._wait_for_completion(batch_id, max_wait_time)
        if not download_url:
            return False
        
        # æ­¥éª¤4: ä¸‹è½½å¹¶è§£å‹ç»“æœ
        return self._download_and_extract(download_url, pdf_file.stem, output_dir)
    
    def _request_upload_urls(self, file_names):
        """ç”³è¯·ä¸Šä¼ URL"""
        url = f"{self.base_url}/api/v4/file-urls/batch"
        
        data = {
            "enable_formula": True,
            "language": "auto", 
            "enable_table": True,
            "files": [{"name": name, "is_ocr": True} for name in file_names],
            "model_version": "vlm"
        }
        
        try:
            print("ğŸ“¤ ç”³è¯·ä¸Šä¼ URL...")
            response = requests.post(url, headers=self.headers, json=data)
            
            if response.status_code == 200:
                result = response.json()
                if result["code"] == 0:
                    batch_id = result["data"]["batch_id"]
                    urls = result["data"]["file_urls"]
                    print(f"âœ… è·å–ä¸Šä¼ URLæˆåŠŸï¼Œbatch_id: {batch_id}")
                    
                    # å­˜å‚¨ä¸Šä¼ URLä¾›åç»­ä½¿ç”¨
                    self.upload_urls = urls
                    return batch_id
                else:
                    print(f"âŒ ç”³è¯·ä¸Šä¼ URLå¤±è´¥: {result.get('msg', 'Unknown error')}")
                    return None
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ ç”³è¯·ä¸Šä¼ URLå¼‚å¸¸: {e}")
            return None
    
    def _upload_pdf_file(self, batch_id, pdf_path):
        """ä¸Šä¼ PDFæ–‡ä»¶"""
        try:
            print("ğŸ“¤ ä¸Šä¼ PDFæ–‡ä»¶...")
            
            with open(pdf_path, 'rb') as f:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªä¸Šä¼ URL
                upload_url = self.upload_urls[0]
                response = requests.put(upload_url, data=f)
                
                if response.status_code == 200:
                    print("âœ… PDFæ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
                    return True
                else:
                    print(f"âŒ PDFæ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    return False
                    
        except Exception as e:
            print(f"âŒ ä¸Šä¼ PDFæ–‡ä»¶å¼‚å¸¸: {e}")
            return False
    
    def _wait_for_completion(self, batch_id, max_wait_time):
        """ç­‰å¾…å¤„ç†å®Œæˆ"""
        url = f"{self.base_url}/api/v4/extract-results/batch/{batch_id}"
        
        print(f"â³ ç­‰å¾…å¤„ç†å®Œæˆï¼ˆæœ€å¤§ç­‰å¾…æ—¶é—´: {max_wait_time}ç§’ï¼‰...")
        start_time = time.time()
        
        while time.time() - start_time < max_wait_time:
            try:
                response = requests.get(url, headers=self.headers)
                
                if response.status_code == 200:
                    result = response.json()
                    
                    if result["code"] == 0:
                        data = result["data"]
                        extract_results = data["extract_result"]
                        
                        for file_result in extract_results:
                            state = file_result["state"]
                            file_name = file_result["file_name"]
                            
                            print(f"ğŸ“Š æ–‡ä»¶ {file_name} çŠ¶æ€: {state}")
                            
                            if state == "done":
                                download_url = file_result["full_zip_url"]
                                print(f"âœ… å¤„ç†å®Œæˆï¼ä¸‹è½½URL: {download_url}")
                                return download_url
                            elif state == "failed":
                                error_msg = file_result.get("err_msg", "Unknown error")
                                print(f"âŒ å¤„ç†å¤±è´¥: {error_msg}")
                                return None
                            elif state in ["processing", "pending", "uploaded"]:
                                # ç»§ç»­ç­‰å¾…
                                pass
                    else:
                        print(f"âŒ æŸ¥è¯¢çŠ¶æ€å¤±è´¥: {result.get('msg', 'Unknown error')}")
                        return None
                else:
                    print(f"âŒ æŸ¥è¯¢çŠ¶æ€è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    return None
                    
            except Exception as e:
                print(f"âŒ æŸ¥è¯¢çŠ¶æ€å¼‚å¸¸: {e}")
                return None
            
            # ç­‰å¾…10ç§’åå†æ¬¡æŸ¥è¯¢
            print("â³ ç­‰å¾…10ç§’åé‡æ–°æŸ¥è¯¢...")
            time.sleep(10)
        
        print(f"âŒ å¤„ç†è¶…æ—¶ï¼ˆ{max_wait_time}ç§’ï¼‰")
        return None
    
    def _download_and_extract(self, download_url, file_stem, output_dir):
        """ä¸‹è½½å¹¶è§£å‹ZIPæ–‡ä»¶"""
        try:
            # åˆ›å»ºZIPå­˜å‚¨ç›®å½•
            zip_storage_dir = Path("/home/wang2go/Code/CNOOC_RAG/CNOOC_RAG/data/00_raw/arxiv_pdf_mineru")
            zip_storage_dir.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºMarkdownè¾“å‡ºç›®å½•
            md_output_dir = Path("/home/wang2go/Code/CNOOC_RAG/CNOOC_RAG/data/01_data/arxiv_md")
            md_output_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¸‹è½½ZIPæ–‡ä»¶
            print("ğŸ“¥ ä¸‹è½½è½¬æ¢ç»“æœ...")
            zip_response = requests.get(download_url)
            
            if zip_response.status_code == 200:
                zip_filename = f"{file_stem}_converted.zip"
                zip_path = zip_storage_dir / zip_filename
                
                with open(zip_path, 'wb') as f:
                    f.write(zip_response.content)
                
                print(f"âœ… ZIPæ–‡ä»¶ä¸‹è½½æˆåŠŸ: {zip_path}")
                
                # è§£å‹ZIPæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                print("ğŸ“‚ è§£å‹ZIPæ–‡ä»¶...")
                temp_extract_dir = zip_storage_dir / f"{file_stem}_temp"
                temp_extract_dir.mkdir(exist_ok=True)
                
                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    zip_ref.extractall(temp_extract_dir)
                
                print(f"âœ… æ–‡ä»¶è§£å‹æˆåŠŸ: {temp_extract_dir}")
                
                # æŸ¥æ‰¾å¹¶ç§»åŠ¨Markdownæ–‡ä»¶åˆ°æŒ‡å®šç›®å½•
                success = self._organize_extracted_files(temp_extract_dir, md_output_dir, file_stem)
                
                # åˆ é™¤ZIPæ–‡ä»¶å’Œä¸´æ—¶è§£å‹ç›®å½•
                print("ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
                zip_path.unlink()  # åˆ é™¤ZIPæ–‡ä»¶
                
                # åˆ é™¤ä¸´æ—¶è§£å‹ç›®å½•
                import shutil
                shutil.rmtree(temp_extract_dir)
                
                print("âœ… ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")
                
                return success
            else:
                print(f"âŒ ä¸‹è½½ZIPæ–‡ä»¶å¤±è´¥ï¼ŒçŠ¶æ€ç : {zip_response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ ä¸‹è½½è§£å‹å¼‚å¸¸: {e}")
            return False
    
    def _organize_extracted_files(self, extract_dir, output_dir, file_stem):
        """æ•´ç†è§£å‹åçš„æ–‡ä»¶"""
        try:
            # æŸ¥æ‰¾Markdownæ–‡ä»¶ - å°è¯•å¤šç§å¯èƒ½çš„æ–‡ä»¶å
            md_patterns = ["**/full.md", "**/*.md", "**/content.md", "**/output.md", "**/auto/*.md"]
            md_files = []
            
            for pattern in md_patterns:
                md_files = list(extract_dir.glob(pattern))
                if md_files:
                    print(f"ğŸ“‹ æ‰¾åˆ°Markdownæ–‡ä»¶ï¼Œæ¨¡å¼: {pattern}")
                    break
            
            if md_files:
                # é€‰æ‹©æœ€å¤§çš„Markdownæ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯ä¸»æ–‡ä»¶ï¼‰
                main_md = max(md_files, key=lambda x: x.stat().st_size)
                target_md = output_dir / f"{file_stem}.md"
                
                # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
                if target_md.exists():
                    target_md.unlink()
                
                # å¤åˆ¶æ–‡ä»¶å†…å®¹ï¼ˆé¿å…è·¨è®¾å¤‡ç§»åŠ¨é—®é¢˜ï¼‰
                with open(main_md, 'r', encoding='utf-8') as src:
                    content = src.read()
                
                with open(target_md, 'w', encoding='utf-8') as dst:
                    dst.write(content)
                
                file_size_kb = target_md.stat().st_size / 1024
                print(f"ğŸ“ Markdownæ–‡ä»¶å·²ä¿å­˜: {target_md} ({file_size_kb:.1f} KB)")
                
                return True
            else:
                print("âš ï¸ æœªæ‰¾åˆ°Markdownæ–‡ä»¶")
                # åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶ä»¥ä¾¿è°ƒè¯•
                all_files = list(extract_dir.glob("**/*"))
                print("ğŸ“ è§£å‹åçš„æ‰€æœ‰æ–‡ä»¶:")
                for file in all_files[:10]:  # æ˜¾ç¤ºå‰10ä¸ªæ–‡ä»¶
                    if file.is_file():
                        size_kb = file.stat().st_size / 1024
                        print(f"   - {file.name} ({size_kb:.1f} KB)")
                
                return False
                
        except Exception as e:
            print(f"âŒ æ•´ç†æ–‡ä»¶å¼‚å¸¸: {e}")
            return False

def main():
    """ä¸»å‡½æ•° - æµ‹è¯•è½¬æ¢åŠŸèƒ½"""
    load_dotenv()
    TOKEN = os.getenv("MINERU_API_TOKEN")
    
    # æµ‹è¯•çš„PDFæ–‡ä»¶è·¯å¾„
    test_pdf = "/home/wang2go/Code/CNOOC_RAG/CNOOC_RAG/data/00_raw/arxiv_pdf/0803.1080.pdf"

    # ä¿å­˜è½¬æ¢åçš„markdowæ–‡ä»¶è·¯å¾„
    output_dir = "/home/wang2go/Code/CNOOC_RAG/CNOOC_RAG/data/01_data/arxiv_md"
    
    # åˆ›å»ºè½¬æ¢å™¨
    converter = MinerUConverter(TOKEN)
    
    # æ‰§è¡Œè½¬æ¢
    success = converter.upload_and_convert_pdf(pdf_path=test_pdf, output_dir=output_dir)
    
    if success:
        print("ğŸ‰ PDFè½¬æ¢å®Œæˆï¼")
    else:
        print("âŒ PDFè½¬æ¢å¤±è´¥ï¼")

if __name__ == "__main__":
    main()

